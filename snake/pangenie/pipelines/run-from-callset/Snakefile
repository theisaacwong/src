configfile:'config.yaml'

## parameters
vcf = config['vcf']
reference = config['reference']
scripts = 'scripts'
# allow max 20 % missing alleles at a variant position
frac_missing = 0.2
outdir = config['outdir']
pangenie_genotype = config['pangenie_genotype']
pangenie_index = config['pangenie_index']
samples = config['reads'].keys()

rule all:
	input:
		expand('{outdir}/pangenome/pangenome.vcf', outdir=outdir),
		expand('{outdir}/genotypes/{sample}-genotypes.vcf', outdir=outdir, sample=samples)



###########################################################
##  Convert VCF into pangenome graph by merging variants ##
##  that are overlapping into multi-allelic positions.   ##
###########################################################

# check that VCF matches the reference genome
rule validate_vcf:
	input:
		vcf = vcf,
		fasta = reference
	log:
		'{outdir}/input-vcf/validate-vcf.log'
	benchmark:
		'{outdir}/benchmarks/validate-vcf.txt'
	conda:
		'env/merging.yml'
	shell:
		"bcftools norm --check-ref e --fasta-ref {input.fasta} {input.vcf} &> {log}"	


# check that VCF is correct and remove positions with more than frac_missing missing alleles
rule prepare_vcf:
	input:
		vcf = vcf,
		validation = '{outdir}/input-vcf/validate-vcf.log'
	output:
		temp('{outdir}/input-vcf/input-missing-removed.vcf')
	log:
		'{outdir}/input-vcf/prepare-vcf.log'
	benchmark:
		'{outdir}/benchmarks/prepare-vcf.txt'
	conda:
		'env/merging.yml'
	shell:
		"cat {input.vcf} | python3 {scripts}/prepare-vcf.py --missing {frac_missing} 2> {log} 1> {output}"


# assign IDs to all alleles
rule add_ids:
	input:
		'{outdir}/input-vcf/input-missing-removed.vcf'
	output:
		'{outdir}/input-vcf/callset.vcf'
	benchmark:
		'{outdir}/benchmarks/add-ids.txt'
	log:
		'{outdir}/input-vcf/callset.log'
	conda:
		'env/merging.yml'
	shell:
		'cat {input} | python3 {scripts}/add-ids.py 2> {log} 1> {output}'


# create biallelic VCF with one record per ALT allele
rule normalize:
	input:
		'{outdir}/input-vcf/callset.vcf'
	output:
		'{outdir}/input-vcf/callset-biallelic.vcf'
	benchmark:
		'{outdir}/benchmarks/callset-biallelic.txt'
	log:
		'{outdir}/input-vcf/callset-biallelic.log'
	conda:
		'env/merging.yml'
	shell:
		'bcftools norm -m- {input} 2> {log} 1> {output}'


# merge variants into a pangenome graph
rule merge_haplotypes:
	input:
		vcf = '{outdir}/input-vcf/callset-biallelic.vcf',
		reference = reference
	output:
		'{outdir}/pangenome/pangenome.vcf'
	log:
		 '{outdir}/pangenome/pangenome.log'
	benchmark:
		'{outdir}/benchmarks/merge-haplotypes.txt'
	conda:
		"env/merging.yml"
	resources:
		mem_total_mb=10000,
		runtime_hrs=4,
		runtime_min=59
	shell:
		"""
		python3 {scripts}/merge_vcfs.py merge -vcf {input.vcf} -r {input.reference} -ploidy 2  2> {log} 1> {output}
		"""



##########################################################
##             Run PanGenie (two steps)                 ##
##########################################################

rule pangenie_preprocessing:
	input:
		vcf='{outdir}/pangenome/pangenome.vcf',
		reference = reference
	output:
		directory('{outdir}/pangenie/indexing/')
	threads:
		24
	resources:
		mem_total_mb=200000,
		runtime_hrs=4,
		runtime_min=59
	log:
		'{outdir}/pangenie/pangenie-indexing.log'
	benchmark:
		'{outdir}/benchmarks/pangenie-indexing.txt'
	params:
		prefix = "{outdir}/pangenie/indexing/index"
	shell:
		"""
		mkdir -p {wildcards.outdir}/pangenie/indexing/
		{pangenie_index} -v {input.vcf} -r {input.reference} -o {params.prefix} -j {threads} -t {threads} &> {log}
		"""


rule pangenie_genotyping:
	input:
		index='{outdir}/pangenie/indexing/',
		reads = lambda wildcards: config['reads'][wildcards.sample]
	output:
		'{outdir}/pangenie/{sample}_graph_genotyping.vcf'
	threads:
		24
	resources:
		mem_total_mb=200000,
		runtime_hrs=4,
		runtime_min=59
	log:
		'{outdir}/pangenie/pangenie-{sample}.log'
	benchmark:
		'{outdir}/benchmarks/pangenie-{sample}.txt'
	params:
		prefix = "{outdir}/pangenie/{sample}_graph"
	shell:
		"{pangenie_genotype} -i {input.reads} -f {input.index}index -o {params.prefix} -j {threads} -t {threads} &> {log}"




##########################################################
##     Convert VCF back to original representation      ##
##########################################################

# represent genotypes in a bi-allelic VCF with one record per ALT-allele
rule convert_back_biallelic_representation:
	input:
		pangenie='{outdir}/pangenie/{sample}_graph_genotyping.vcf',
		panel='{outdir}/input-vcf/callset.vcf'
	output:
		'{outdir}/pangenie/{sample}_genotypes-biallelic.vcf'
	resources:
		mem_total_mb=20000
	benchmark:
		'{outdir}/benchmarks/{sample}-convert-to-biallelic.txt'
	shell:
		'cat {input.pangenie} | python3 {scripts}/convert-to-biallelic.py {input.panel} > {output}'

rule compress_vcf:
	input:
		"{filename}.vcf"
	output:
		"{filename}.vcf.gz"
	shell:
		"""
		bgzip -c {input} > {output}
		tabix -p vcf {output}
		"""


# represent genotypes in the same way as in the input callset
rule convert_back_original_representation:
	input:
		pangenie='{outdir}/pangenie/{sample}_genotypes-biallelic.vcf.gz'
	output:
		'{outdir}/genotypes/{sample}-genotypes.vcf'
	benchmark:
		'{outdir}/benchmarks/{sample}-convert-to-original.txt'
	resources:
		mem_total_mb=10000
	conda:
		"env/merging.yml"
	shell:
		'bcftools norm -m+ {input.pangenie} > {output}'
